Wir wollen Erkenntnisse generieren, die möglichst eben nicht von solchen Verzerrungen und Effekten, die ich eben im Video erklärt habe, beeinflusst sind und um das zu erreichen, gibt es Gütekriterien. Gütekriterien eben für wissenschaftliche Untersuchung. Allen voran die drei Hauptgütekriterien Objektivität, Reliabilität und Validität. Die Objektivität schreibt also, dass eine Untersuchung eben unabhängig von den räumlichen Bedingungen und oder dem Versuchsleiter, der Versuchsleiterin zu denselben Ergebnissen kommt. Sprich, das Experiment, was ich gemacht habe, muss, wenn ich das in ein anderes Labor bringe, wenn es ein anderer Versuchsleiter oder eine andere Versuchsleiterin durchführt, sollte es eben zu denselben Ergebnissen kommen. Auch wenn ich die gleiche Population teste. Reliabilität spiegelt dann den Grad der Messgenauigkeit wieder. Wie genau messe ich eigentlich das, was ich da abfrage? Wenn ich sie heute zweimal nach ihrem Alter frage und sie mir zweimal irgendwie 29 sagen, naja, dann war das eine genaue Messung sozusagen, weil sie mir zweimal das gleiche gesagt haben. Und die Validität gibt dann an, ob das tatsächlich erfasst wurde, was ich erfassen wollte in meiner Studie. Also, wenn ich wissen wollte, wie alt sie in Jahren sind, ich frage sie, wie alt sie sind, sie sagen mir das, naja, dann ist es valide, weil ich halt damit gemessen habe, wie alt sie sind. Da ist es ja relativ simpel. Diese Gütekriterien, die bauen aufeinander auf. Das heißt, dass hohe Reliabilität nur dann erreichbar ist, wenn ich eine hohe Objektivität habe. Reliabilität und Validität mache ich gleich noch mal ein Beispiel. Genauer gucken wir uns zunächst die Objektivität noch mal genauer an. Wir können hier noch mal unterscheiden in die Durchführungsobjektivität. Das heißt, dass die Ergebnisse unabhängig von der Person des Versuchsleiters oder der Versuchsleiterin eben unabhängig ist. Das schaffen wir eben dann, zum Beispiel, wenn ich einen Fragebogen habe, dann ist das natürlich maximal standardisiert, wenn ich jedem den gleichen Text und den gleichen Fragebogen gebe. In vielen Laborstudien ist es dann so, dass eben die Art, wie der Experimentator, die Experimentorin, also die Versuchsleitende Person eben mit den Versuchspersonen umgeht, was sie ihnen sagt, dass man das so hoch wie möglich standardisiert, dass man das festschreibt, wie man eben auf bestimmte Sachen reagiert. Auswertungsobjektivität ist eben, dass ich das gleiche Verhalten einer Testperson dann auch auf gleiche Weise auswerte. Dann geht es schon über in die Interpretationsobjektivität, dass diese, die ich aus der Auswertungsobjektivität erhaltenen Testwerte eben auf gleiche Weise auch interpretiert werden. Bleiben wir nochmal bei dem Beispiel des Fragebogens. Wenn ich da jetzt, wenn sie dort Ja oder Nein ankreuzen sollen auf einem Fragebogen, sind sie älter, sind sie 30 oder älter, dann können sie da Ja oder Nein ankreuzen. Dann habe ich eine hohe Durchführungsobjektivität, habe eine hohe Auswertungsobjektivität, weil ja jeder sieht, okay, das ist sozusagen das Ankreuzen, ihr Verhalten, das, was ich beobachte, das, was ich gemessen habe dort, das Kreuzchen, welches sie gesetzt haben, und das kann jeder auf die gleiche Weise auswerten und jeder, der zählen kann, kann dann eben zählen, wie viele Leute eben angekreuzt haben, dass sie 30 oder älter sind. Bei offenen Antwortkategorien, wo sie einen Text schreiben können, dann kann es eben schon wieder von verschiedenen Personen verschieden interpretiert werden, wenn es keine Normen gibt oder wenn es keine Vorüberlegung gibt, wie mit bestimmten Stichworten zum Beispiel umzugehen ist, die in verschiedenen Kategorien zu werfen. Ein bekanntes Beispiel für diese, für Objektivität und im Prinzip auch der Durchbruch für experimentelle Psychologie, stellt der kluge Hans beziehungsweise der kluge Hans-Effekt dar. Der kluge Hans war ein Pferd, das können Sie sich gerne im Internet nochmal genau sonst durchlesen, das ist ein Pferd, was angeblich rechnen konnte. Und das wurde halt untersucht, da gab es dann sogar eine 13-köpfige Expertenkommission, die da hingefahren ist, Anfang, da steht es, Oscar Pfungst, 1904, beziehungsweise 1895 von Wilhelm von Osten, Ostens Pferd, der kluge Hans, das rechnen konnte. Und es sah dann so aus, wir sehen hier unten jetzt so ein Bild, ich mach mal den Laserpointer an, dass hier eine Person da ist und irgendwie sagt, was er berechnen muss. Ja, und man hat auch dann vermieden, dass das Pferd immer nur von dem Versuchsleiter selbst, von dem von Osten selbst die Aufgaben gestellt bekommen hat, sondern eben auch von anderen die Aufgaben bestellt bekommen hat. Und trotzdem hat das Pferd irgendwie in 90 Prozent der Fälle richtig mit den Hufen so geklopft, was das Ergebnis ist. Also wenn jetzt einer gezeigt hat, rechnen wir bitte 2 plus 2, hat das Pferd eben viermal mit den Hufen geklopft. Ja, man könnte also jetzt meinen, dass das durchaus objektiv war. Es hat ja, verschiedene Leute haben das Experiment durchgeführt, es lag anscheinend nicht am Versuchsleiter, weil ja verschiedene Versuchsleiter zu demselben Schluss kamen, dass dieses Pferd nun rechnen konnte. Und das hat es ja auch immer wieder gezeigt. Allerdings, 1904 kam man auf die Lösung dieses Phänomens des Pferdes, in dem sich nämlich herausstellte, dass das Pferd einem sehr sensibel darüber war, die Anspannung von Menschen festzustellen. Und der Versuchsleiter, auch wenn er noch so verschieden war, kannte, weil es relativ einfache mathematische Formeln waren, kannte die Lösung und hat daraufhin wohl eine gewisse Anspannung gezeigt, wie häufig wohl das Pferd nun klopfen möge, und eine gewisse Entspannung gezeigt, wenn das Pferd die richtige Anzahl hatte. Und somit wusste das Pferd, aha, an der Stelle sollte ich aufhören. Und das gibt schon den Wink am Ende, dass wir, oder das ist ein Gütekriterium, der Doppelblindstudie, der Versuchsleiter hier in dem Falle, wusste eben immer die Antwort, wusste, was er sozusagen erwartet. Das konnte, glaube ich, letztlich nie als Doppelblindstudie durchgeführt werden. Das lesen Sie aber im Zweifel noch mal durch. Aber wir sehen, dass wir, wenn wir eben auch so Medikamentenstudien und so weiter, da kommt ja meistens der Begriff der Doppelblindheit vor, dass eben der Versuchsleiter, derjenige, der das Medikament verabreicht, eben nicht weiß, was das für eine, ob das Medikament eben ein Placebo ist oder eben nicht ist, weil schon das zu einer Veränderung der Untersuchungssituation, oder des Ergebnisses führen kann. Ja, ich habe es gerade schon angeschnitten, Objektivität und im Grunde damit auch Reliabilität kann eben durch eine Standardisierung erreicht werden. Ein Standard ist eine vergleichsweise einheitliche oder vereinheitliche und auch weithin anerkannte Art und Weise, etwas herzustellen, durchzuführen. Das laut Definition standardisiert, ich habe es schon angesprochen, können eben Fragebögen sein. Objektiv kann eben dann auch sein, wenn der Versuchsleiter nicht über die Hypothese informiert wird, also er weiß gar nicht, in welcher Versuchsbedingung die Versuchsperson, die er gerade begrüßt, eben sind. Und natürlich, ein Fach Blindstudien ist, dass die Teilnehmer und Teilnehmerinnen das Ziel der Untersuchung als solches nicht kennen. Doppelblind sind tatsächlich zumindest etliche Studien, die von Studierenden durchgeführt werden und so weiter nicht, weil man selbst häufig als Versuchsleiter auftritt und natürlich man selber eben weiß, an was man eigentlich gerade forscht und in welcher Gruppe die Studierenden sind. Dann hilft man sich aber eben mit der Standardisierung des Experiments, eben zum Beispiel durch Fragebögen, durch die Standardisierung von so einem Interview oder auch der Instruktion, dass man die Instruktion vorliest oder sich halt bewusst macht, welche Punkte man abarbeiten muss, damit man eben immer und jede Versuchsperson gleich behandelt. Ja, Objektivität und Standardisierung in dem Falle, um die Objektivität zu erreichen, bedeutet aber eben auch, dass man vorher festlegt, bevor man zum Beispiel so ein Experiment macht, wie ich es am Ende auswerten und interpretieren möchte. Und ehrlich gesagt, nicht selten ist man als Forscher dessen unterlegen oder der Versuchung, die Versuchung liegt nahe, dass man eben Daten erhebt und am Ende sich mal in die Daten reinschaut und dann die Daten so versucht auszuwerten, dass sie vielleicht zu der Hypothese passt, die man haben möchte. Ich fürchte, es ist nicht selten, dass es also ein Appell an jeden Forscher und an jede Forscherin ist, sich vor der Untersuchung genau festzuhalten, was man misst. Okay, das weiß man meistens und könnte man das Experiment nicht machen, aber dann eben auch festzulegen, okay, ich kriege solche Daten raus. Das kann man ja alles vorher schon berechnen, Pseudodaten. Man kann all die Statistik, die man später machen möchte, all die Grafik, die man machen möchte, kann man vorher schon mit Pseudodaten sich in Excel, R, SPSS, wo auch immer schon generieren und dann eben mit den tatsächlich erhobenen Daten füttern. So kann ich sicherstellen, dass ich am Ende eben nicht mal drauf schiele oder die Grafiken sehen ja doch nicht so aus, wie ich dachte. Ah, ich wollte ja auch eigentlich erst Reaktionszeiten ab 10 Millisekunden messen und nicht schon ab 0 Millisekunden oder sowas. Sowas ist ja schnell gemacht, deswegen sollte man das eben vorher festlegen, standardisieren, was man eben macht. Dazu gehört aber auch, dass ich jetzt nochmal einen Schritt sozusagen zurück, nicht nur die Auswertung, sondern auch vorher schon, dass ich eben die Begriffe, die ich benutze, die zentralen Begriffe genau definiere. Wir haben zum Beispiel in dem Experiment im Hörsaal hier mit den Sitzreihen genau operationalisiert, was bedeutet für uns vorne sitzen, was bedeutet für uns hinten sitzen. Das haben wir anhand der vier Reihen hinten und der vier Reihen vorne operationalisiert. Wir bestimmen, welche relevanten Variablen wollen wir eigentlich erheben. Das war dann eben, dass wir einmal die Sitzreihen hatten und einmal das, wie häufig sich jemand meldet, wobei man noch festlegen könnte, ja, was gilt denn als Meldung? Gilt eine Meldung, können Sie bitte das Licht heller machen schon als Meldung, oder müssen es eben die inhaltlichen Meldungen sein? Die Vorgehensweise ist auch Auswahl geeigneter Methoden zur empirischen Überprüfung. In unserem Hörsaal-Experiment ist es relativ einfach, dass wir es eben zählen, wie viele Meldungen es gibt. Das ist die Datenerhebung, dass wir das zählen, aber es kann eben auch andere Methoden geben. Vielleicht sollte jemand anderes für uns zählen, nicht derjenige, der gerade vorne steht, weil er sich vielleicht verzählen könnte. Am Ende regeln wir, das hatte ich gerade gesagt, wie wir das auswerten und interpretieren wollen. Die Daten und in jeder Disziplin eigentlich ungeliebt dokumentieren das, weil nur durch eine Dokumentation dessen, wie wir den Forschungsprozess gemacht haben, also wie wir standardisiert haben, wie wir das durchgeführt haben, nur die Dokumentation der Durchführung erlaubt es, dass am Ende das Experiment von anderen Forscherinnen und Forschern eben nachempfunden werden kann. Und ehrlich gesagt verstehe ich überhaupt nicht, warum Reliabilitätsstudien in Journals relativ schlecht wegkommen. Dann heißt es, dass man nicht genügend neue Wissenschaft produziert hat. Derweile ist es sehr wichtig, dass man Daten, dass man Sachen auch replizieren kann, dass man Studien replizieren kann. Ich habe selber Replikationsstudien gemacht, um eben meine eigene Forschung auf ein gutes Fundament zu stellen, dass ich dem sozusagen glauben kann, was andere Forscher auch herausgefunden haben, wenn es nur wenige Experimente zu Sachen gibt. Das können ja, wir haben es gesehen, Zufallsbefunde sein. Und wenn es schlecht dokumentiert ist, fällt es natürlich denjenigen, die das replizieren wollen, auch enorm schwer, das replizieren zu können. Und plötzlich ist es eben nicht mehr objektiv, weil wenn es jemand anders nicht replizieren kann, macht er vielleicht eben irgendetwas anders, kommt zu einem anderen Ergebnis. Und am Ende weiß man nicht, warum kommt er zu einem anderen Ergebnis. Daher ist die Dokumentation ebenso wichtig. Beispiele für standardisierte Erhebungssituationen haben wir ja schon gesagt. Zum Beispiel standardisierte Fragebögen, dass der Versuchsleiter nicht unbedingt weiß, nicht über die Hypothesen informiert ist. Wir haben gesehen, praktisch ist das in manchen Situationen nicht mehr möglich. Vielleicht in manchen auch nicht immer unbedingt notwendig, wenn man sich eben selber gut standardisieren kann oder solch Blätter ausgibt und so weiter. Und dass die Teilnehmer eben das Ziel der Untersuchung erst nach der Erhebung erfahren. Übrigens, das sollten sie allerdings auch hinter jeder, nach jeder Untersuchung. Dazu haben sie ja ein Recht zu wissen, was sie da jetzt eigentlich, wofür sie ihre Zahl, also es ist ja auch nur höflich ihnen zu sagen, hier, das war der Grund, warum du jetzt uns geholfen hast. Das war eigentlich das Anliegen unserer Untersuchung. Ja, Reliabilität und Validität. Ich habe gesagt, ich mache es gleich nochmal genauer. Reliabilität, die Zuverlässigkeit, mit der ein Testverfahren das zu messende Merkmal genau misst. Üblicherweise zum Beispiel ist eine Waage, ist reliabel. Ja, so eine Körperwaage, auf die stellen sie sich drauf und auf die stellen sie sich in fünf Minuten drauf und wenn sie in den fünf Minuten nichts Anstrengendes gemacht haben, nichts gegessen haben, dann zeigt die das Gleiche, wie was sie vor fünf Minuten gezeigt hat. Sie ist reliabel, weil sie eben bei einer Messwiederholung zu konsistenten Resultaten führt. Jetzt könnte es aber sein, dass ich mit der Waage, ich meine, ihnen ist völlig klar, dass man mit einer Waage eben das Gewicht misst. Ja, wenn ich mich da drauf stelle, bekomme ich eben ein Gewicht heraus. In der Psychologie haben wir latente Merkmale, wir sehen also nicht unbedingt, das ist nicht hundertprozentig klar, ob wir mit einem Intelligenztest tatsächlich Intelligenz messen oder ob wir nicht doch auch anderes messen oder zumindest mitmessen. Da geht es um die Messfehler. Jede Messung, die wir machen, ist mit einem Messfehler behaftet. Jetzt gibt es natürlich Wissenschaften, bei denen sind die Messfehler nicht ganz so stark. Physik hat zum Beispiel sehr, sehr genaue Messinstrumente, während unsere Messinstrumente in der Psychologie, muss man schon so festhalten, wir können nicht von einer sehr hohen Reliabilität bei uns ausgehen, zumindest nicht verglichen mit anderen Naturwissenschaften. Ja, und dann kommt noch das dazu, dass wenn wir eben nicht genau, wenn wir eben solche latenten Merkmale haben, wenn wir eben nicht genau beobachten können, nicht sichtbar ist, was wir eigentlich messen, sondern wir immer von so Konstrukten reden, die man eben nie direkt beobachten kann, dann ist immer die Frage, ob wir überhaupt das messen, was wir messen wollen. Ja, da kommen wir zur Gültigkeit und zur Validität, bezeichnet also den Grad der Gültigkeit, mit der ein Test dasjenige Merkmal oder das Verhalten misst, was es zu messen vorgibt. Stellen Sie sich vor, in der Psychologie ist es im Prinzip so, dass wir womöglich mit einem unserer Messinstrumente, ja, sagen wir, wir hätten ein Messinstrument, was eine Waage ist. So, und da stellen wir jetzt einen Menschen drauf und tatsächlich wollen wir, glauben wir aber, dass wir mit der Waage die Körperhöhe messen würden. Es wird gar nicht so verkehrt sein, weil die Messhöhe, die Körperschwere, ja, durchaus korreliert mit der Körperhöhe. Das heißt, wir könnten bei Messungen annehmen, ja, wir haben hier mit unserer Waage anscheinend die Körperhöhe gemessen. Tatsächlich haben wir dann aber die Körperschwere gemessen. Das ist also ein, wenn wir eben nicht direkt beobachten können, durchaus ein Problem. Dafür brauchen wir eben diese Gütekriterien. Die können wir auch messen oder wir können eben davon ausgehen, wann etwas valide ist oder nicht. Da gibt es verschiedene Arten von Validität. Da gibt es auch verschiedene Arten von Reliabilität, die ich schon genannt habe, dass ich eben vielleicht so einen Rehtest mache, ja, dass ich den Test zweimal mache und dann kommt eben beim zweiten Test das gleiche aus wie beim ersten. Ja, aber dann stellen Sie sich vor, hohe Reliabilität durchaus, gut validierte Messinstrumente, wie zum Beispiel Persönlichkeitsfragebögen, Intelligenztest. Wenn ich dort eine Frage habe, die eben doch irgendwie ein bisschen missverständlich ist, kann es eben sein, dass Sie heute, obwohl sich Ihre Persönlichkeit nicht geändert hat, Ihre Intelligenz nicht geändert hat, stelle ich Ihnen eine Frage und heute antworten Sie eben irgendwie auf so eine Ratingskala. Keine Ahnung, wie zufrieden sind Sie mit Ihrem Studium? Sie sind eigentlich an zwei Tagen gleich zufrieden damit. An dem einen Tag sagen Sie vier, an dem anderen Tag sagen Sie fünf, dann ist es eben nicht super reliabel, weil Sie eben zwei unterschiedliche Angaben dann gemacht haben und vielleicht hat Ihnen einfach nur an dem einen Tag der Kaffee nicht geschmeckt, was aber nicht großartig mit Ihrem Studium zu tun hat. Gut, da kann man sich jetzt streiten, wie sehr der Kaffee mit dem Studium zu tun hat, aber vielleicht verstehen Sie, worauf ich hinaus möchte, dass eben noch andere Einflüsse eine Rolle spielen können, Ihre Müdigkeit oder was auch immer eine Rolle spielen kann, die eben die Messung ungenauer macht. Ich sagte, die Gütekriterien bauen aufeinander auf, das heißt also auch, dass die Reliabilität auf die Validität aufbaut, denn wenn ich, bleiben wir bei dem Beispiel der Waage, mit der wir die Körperhöhe messen wollen, ich werde halt sehr viele Messfehler haben. Wenn ich ein Instrument habe, was eben nicht valide ist, werde ich eben auch viele Messfehler, viel Streuung in meinen Daten generieren. Deswegen der Aufbau Objektivität, Reliabilität und Validität, die aufeinander aufbauen. Ja, ich habe es schon bei der Objektivität anklingen lassen, dass es relevant ist, die zentralen Begriffe, die wir benutzen, eben zu definieren. Also zum Beispiel das interessierende Merkmal oder Konstrukt, das zu definieren, ist eminent wichtig, aber manchmal eben auch schwierig, weil verschiedene theoretische Ansätze können eben einen Begriff auch auf verschiedene Art und Weise beschreiben. Dann muss man sich eben auf eine Definition einigen. Manchmal erschwert es eben auch die Umgangssprache, die man hat. Erschwert es manchmal auch, Sachen tatsächlich so zu definieren, eben theoriegeleitet zu definieren. Viele Definitionen, die man so ansieht, gerade wenn sie aus einem Sprachkontext herauskommen, haben dann keinen Bezug zur Empirie. Das heißt, dass die nicht genutzt werden können, um irgendwie etwas eindeutig festzulegen oder eindeutig herauszufinden, sprich, dass man daran eben keine Hypothese ableiten kann. Aber um eine Hypothese ableiten zu können, muss ich eben die Definition festziehen sozusagen, also eine ausreichend gute Definition machen, um die Hypothese festzuleiten. Wir hatten es gesehen anhand der Wortmeldungen und der welche Sitzreihe wir haben. Nehmen wir mal zum Beispiel, kommen wir mal zu dem Beispiel dessen, Intelligenz zum Beispiel. Im Grunde hier in der Wikipedia steht zum Beispiel, dass die Intelligenz, die im weitesten Sinne die Fähigkeit zum Erkennen von Zusammenhängen und zum Finden optimaler Problemlösung dient, also dass die Intelligenz das beschreibt. Würde ich jetzt erstmal nicht dagegen sprechen. Das klingt mir auch rein sprachlich, wenn wir jetzt erstmal grundsätzlich das Konzept der Intelligenz verstehen wollen, ist das ja eingängig. Binet und Simon im 1905 sagen, Intelligenz ist die Art der Bewältigung einer aktuellen Situation. Sicherlich auch nicht ganz verkehrt. Oder Stern 1950, Intelligenz ist das Vermögen, Bedingungen des Lebens selber umzugestalten und produktive Leistung zu erbringen. Das sind halt alles Definitionen, die für sich sicherlich verständlich sind, die man so auch in einem Wörterbuch zum Beispiel schreiben kann, was uns ermöglicht, die Welt irgendwie erstmal zu begreifen. Das wir definieren für uns. Aber Hypothesen daraufhin abzuleiten, ist gar nicht so leicht. Und gerade in dem Bereich hat sich die Psychologie am Ende auf folgende Definitionen einigen. Intelligenz ist das, was der Intelligenztest ist. Black und Hutter 2007 listen sogar ganze 70 Definitionen für Intelligenz auf. Und für eine empirische Überprüfung von solchen Theorien ist eben eine genaue Definition der wichtige erste Schritt. Nur so können wir überhaupt theoretische Ansätze miteinander vergleichen und eben Unterschiede in so verschiedenen Theorien erkennen. Und bei der Intelligenz, ich habe es vielleicht auch schon gesagt, was der Intelligenztest misst, ist okay. Aber es kann natürlich sein, dass der Intelligenztest so Sachen mitmisst, wie ihre Leistungsmotivation oder auch wie müde sie heute sind, wie gut sie sich konzentrieren können. Das ist das, was ich hier auf der nächsten Folie habe, schon mehrfach angesprochen habe, als dieses eine Spezialproblem der Psychologie, dass wir latente Merkmale haben, die nicht beobachtbar sind. Hier steht schon, Intelligenzausprägung kann mithilfe verschiedener Teilleistungstests auch ermittelt werden. Dass ich verschiedene Leistungstests mache und am Ende irgendwie auf etwas, was ich als Intelligenz bezeichne, schließe. Es gibt natürlich aber auch genügend objektive, also Manifeste-Merkmale, die ich beobachten kann. Wir haben ja nicht nur Konstrukte, die so latent sind, zum Beispiel lässt sich Ausprägung, Geschlecht, vor allem auch Größe sehr wohl direkt beobachten. Und wenn ich dann eben meine Definition von dem Konstrukt habe, was ich untersuchen möchte, dann kann ich mich eben an die Operationalisierung machen, was wir jetzt schon mehrfach gehört haben. Weil erst dann, wenn ich etwas operationalisiert habe, erst dann kann ich es eben auch messen. Und durch die Operationalisierung gelange ich eben zu einer Standardisierung, weil ich sage, okay, jetzt hintere Sitzreihe sind eben vier Leute, die Meldung ist eben inhaltlich. Wenn ich das standardisiert habe, kann ich eben zu Reliabilität und auch Validität gelangen. Hier steht, zur Operationalisierung eines theoretischen Konstrukts gehört auch die Frage, welches Messniveau diese verwendeten Indikatoren haben können. Das schauen wir uns gleich an. Ich nehme erst mal ein Beispiel, und zwar kennen Sie bestimmt den Turing-Test, 1950 von Alan Turing, eigentlich Mathematiker und Logiker. Da stellte sich die Frage, können Maschinen denken? Tja, und Sie sehen, was ist eigentlich Denken? Was stellen wir uns unter Denken vor? Was genügt es irgendwie, eine Maschine zu bauen, die Denken nachbilden kann? Woran würden wir das erkennen, wenn wir eine solche Maschine hätten? Na gut, er formalisiert es, Mathematiker formalisiert es, die Fragestellung und sagt, gibt es eine Maschine, die erfolgreich die Rolle von einem Menschen, den wir A nennen, in einem Imitationsspiel spielen kann. Also er hat jetzt hier einen Menschen A, einen Befrager und einen Computer, und hiermit umgeht er dann solche, vielleicht auch schwammigen Begriffe, wie Intelligenz, wie Denken, wie Bewusstsein und definiert damit implizit, dass eine intelligente Maschine erfolgreich das Imitationsspiel spielen kann. Das ist seine Definition, wenn auch implizit in dem Falle. Operationalisiert wird es dann daran, dass man eben Regeln aufstellt für dieses Imitationsspiel und damit kann man eben diese, mehr oder weniger künstliche Intelligenz, messbar machen. Weil man sagt, okay, wie messe ich es? Ich messe es, indem ich ein Imitationsspiel mit bestimmten Regeln mache. Und diese Messung, die ich dann habe, die ich dann durchführe in diesem Imitationsspiel, die soll eben so weit wie möglich objektiv und wiederholbar, sprich vergleichbar sein, sprich standardisiert sein. Ja, und ich sagte schon, wenn ich jetzt eben Daten erhebe, wenn ich etwas messe, dann bestimmt das Skalenniveau, also die Art und Weise, wie ich das Konstrukt messe, was ich da messe, zum Beispiel, wenn ich etwas zähle, was ich beobachte, beschreibt, welche Aussagen ich später treffen kann. Und um dieses Skalenniveau und die Aussagen, die wir dann treffen können, schauen wir uns im nächsten Video an.
