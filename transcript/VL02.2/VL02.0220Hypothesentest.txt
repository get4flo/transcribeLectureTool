Wir können im Grunde zwei Hypothesenarten unterscheiden, einmal die Unterschiedshypothesen und zum anderen die Zankenzusammenhangshypothesen. Unterschiedshypothesen, das sind Hypothesen für Häufigkeits- beziehungsweise Mittelwertsvergleiche. Hier auf der Folie steht, postulieren ein Unterschied zwischen Merkmalen, der auf der unterschiedlichen Zugehörigkeit zumindest in zwei Populationen zurückzuführen ist. Zum Beispiel, man könnte zum Beispiel sagen, zwei oder mehr Populationen unterscheiden sich in Bezug auf ein bestimmtes Merkmal. Zum Beispiel, wir hatten das mit den Studierenden, die in der vorderen Reihe sitzen, das ist Population 1 und wir haben uns gefragt, ob diese Population 1 eben in Vorlesung mehr Fragen als Studierende in den hinteren Reihen, Population 2, stellt. Das ist eine klassische Unterschiedshypothese. Oder eine Maßnahme, also ein Treatment, hat einen Einfluss auf ein Merkmal. Ein Treatment führt zum Beispiel zu einer Merkmalsveränderung, ja also zum Beispiel, Lernen-Treatment verbessert die Leistung. Das ist die Leistung, das Merkmal und wir messen eben die Veränderung der Leistung durch das Lernen, auch eine Unterschiedshypothese. Oder auch zwei Maßnahmen, das heißt zwei Treatments, Treatment A1 und A2, unterscheiden sich in ihrer Wirkung auf ein Merkmal. Zum Beispiel also, machen wir es konkreter, Lernen in Gruppen hat bessere Wirkung auf die Leistung, die Leistung ist also das Merkmal, Lernen in Gruppen hat bessere Auswirkung auf die Leistung als Lernen alleine. Wir haben also zwei Treatments, Lernen in der Gruppe, Lernen alleine und untersuchen, in welchen der beiden Treatments am Ende mehr Leistung herauskommt. Die Zusammenhangshypothese, das sind Hypothesen, die sich auf Zusammenhänge zwischen zwischen Merkmalen beziehen. Zum Beispiel, je weiter vorne Studierende sitzen, desto häufiger stellen sie Fragen. Wichtig ist, wird eine Beziehung zwischen zwei Variablen bestätigt, darf diese nicht im Sinne einer Kausalbeziehung interpretiert werden. Wir hatten das vorhin mit Scheinkorrelation. Auch wenn sprachlich natürlich die Formulierung der Hypothese dies halbwegs nahe legt. Diese Art der Hypothese beeinflusst, also die Art der Hypothese beeinflusst letztlich alle weiteren Schritte im wissenschaftlichen Forschungsprozess, also wie zum Beispiel die Wahl, wie das getestet wird oder wie die Methode aussieht, wie das Experiment auszusehen hat, wie man die Daten erheben möchte. Ich kann es nicht häufig genug sagen. Hypothesen beinhalten also allgemeingültige Aussagen bezüglich bestimmter Populationen. So, diese Populationen. In aller Regel kann man eine Population nicht vollständig untersuchen, sondern eben immer nur Auszüge, sprich Stichproben aus einer Population untersuchen. Wenn meine Population natürlich wäre, dass sie jetzt meine Population wäre, also die 460 Leute, die sich jetzt vielleicht hier in die Vorlesung setzen, dann könnte ich das noch schaffen, diese komplette Population zu untersuchen. Dann kann ich aber eben immer nur Aussagen über sie, also diese 460 Leute machen. In der Regel aber möchte man Aussagen über Populationen treffen, die deutlich größer sind, meistens sogar über die gesamte Menschheit oder über alle Deutsche, über alle Europäer und so weiter. Und da kann man ja nicht alle Millionen oder gar Milliarden Menschen befragen oder einem Test unterziehen. Deswegen zieht man eben aus dieser Population Stichproben. Im besten Falle zieht man eben zufällige und repräsentative Stichproben, damit die Zusammensetzung der Stichprobe möglichst genau mit der Zusammensetzung der Population übereinstimmt. Da eben nie alle Populationsmitglieder erfasst werden können, ist so eine endgültige Aussage, auch ein endgültiges Verifizieren und Falsifizieren im Grunde nicht möglich. Wir hantieren also immer mit statistischen Prüfgrößen. Also wir legen wissenschaftliche Prüfkriterien fest, ab wann wir eine probabilistische Hypothese anhand der empirischen Daten annehmen oder sie verwerfen. Schauen wir uns also diesen Prozess der Hypothesenbildung nochmal an. Wir hatten die Beobachtung, wir haben eine Beobachtungshypothese aufgestellt, die war dann eben induktiv und wir bilden eben auch aus anderen bestehenden Theorien eine statistische Hypothese, die eben die kritische Untersuchung zur Hypothesenprüfung ermöglicht. Wir machen zum Beispiel ein Experiment oder eine Beobachtung, um schließlich eine Schlussfolgerung zu treffen, vielleicht eine Theorie zu bilden oder zu erweitern. Dann haben wir eben die Theorie und können uns dann wieder, diese Theorie geht vielleicht ein in ein Theoriensystem, erweitert andere Theorien und so weiter und aus dieser Theorie heraus, diesen Rückschluss, den wir machen, können wir vielleicht wieder neue Fragen erstellen und dann sind wir eben nicht mehr im induktiven Bereich, sondern im deduktiven Bereich, weil diese neuen Fragen, die sich aus der bisherigen Forschung, aus der bisherigen Theorie ableitet, eben überführt werden in neue statistische, also in neue Hypothesen, die wir eben in Statistik überprüfen können. Sie lesen hier H0 und H1. Das steht für die Nullhypothese und die Alternativhypothese. Gucken wir uns auf der nächsten Folie an hier. Wir gehen also, wie heute schon so häufig gesagt, nach dem Falsifikationsprinzip vor. Wir bilden eine Alternativhypothese, wir formulieren eine Alternativhypothese. Der könnte lauten, wenn Studierende in den vorderen vier Reihen sitzen, dann stellen sie mehr Fragen als Studierende, die in den hinteren vier Reihen sitzen. Nun wird angenommen, dass diese H1, diese Alternativhypothese, dann zutrifft, wenn gezeigt wird, dass das gegebene Ergebnis unter der H0, unter der Nullhypothese sehr unwahrscheinlich ist. Schauen wir uns die H0 dafür an. Die können wir, wir formulieren also genauso, nicht nur eine H1, nicht nur eine Alternativhypothese, sondern wir formulieren auch die Nullhypothese, H0, die im Prinzip den Status Quo beschreibt. Wenn Studierende in den vorderen vier Reihen sitzen, dann stellen sie genauso viele oder weniger Fragen als Studierende, die in den hinteren vier Reihen sitzen. Das ist der Status Quo. Und dass die Alternative Welt, die wir nun sozusagen testen wollen, ob die stimmt, während wir im Moment noch davon ausgehen, dass diese hier stimmt. Die in der H1 erwartete Beziehung zwischen den untersuchten Variablen, also die Sitzordnung, ist die unabhängige Variable und die Anzahl der Fragen, die gestellt werden, ist die abhängige Variable. Und diese Beziehung zwischen den untersuchten Variablen besteht eben in der Nullhypothese nicht, weil eben genauso viel oder sogar weniger gefragt wird. Formulieren wir es nochmal um. Wir probieren also zu zeigen, dass mit größtmöglicher Sicherheit, also mit hoher Wahrscheinlichkeit, die Nullhypothese falsch ist. Und wenn diese falsch ist, gehen wir davon aus, dass die Alternativhypothese zutrifft. Es können allerdings auch Hypothesen, also auch Nullhypothesen, nicht endgültig widerlegt werden. Es besteht dabei immer die Möglichkeit, dass wir uns Fehlentscheidungen, dass es Fehlentscheiden. Es ist halt sozusagen ein Restrisiko, bleibt immer nur, man versucht es so gering wie möglich zu halten, dass man sich eben in fälschlicher Weise für die Alternativhypothese, also für die Welterklärung, Studierende vorne stellen mehr Fragen als Studierende hinten, festlegt oder die jetzt als gültig empfindet. Wir wollen also Aussagen über eine Population treffen, also zum Beispiel über alle Studierende der Welt. Und diese Population ist eben die Menge aller potenziellen Untersuchungsobjekte, von denen wir eben natürlich nicht alle testen können. Typischerweise ist es in der Statistik so, dass man griechische Buchstaben dann verwendet, wenn man eben Aussagen über die Population trifft und später lateinische Buchstaben, wenn wir eben über Werte der Stichprobe reden. Die Nullhypothese, die wir hier zum Beispiel formuliert haben, ist, dass das µ0, also das µ in der Nullhypothese, also wenn die Welt, und zu sagen, wenn wir in einer Welt lebten, in der die Nullhypothese stimmt, in der die Nullhypothese gilt, dann würden wir eben davon ausgehen, oder dann würde gelten, dass die Vorderen, die Anzahl der Fragen, die die Studierenden vorne, die vorne sitzen, stellen, minus die Anzahl der Fragen, die die hinten stellen, eben 0 oder sogar kleiner ist, die Differenz. Sprich, die, die vorne sitzen und die, die hinten sitzen, gleich viel, wenn wir sagen, gleich 0, gleich viele Fragen stellen. Wenn wir aber in einer Welt leben, in der die Alternativhypothese H1 gilt, dann würde diese Differenz aus den Vornesitzenden minus den, die hinten sitzen, eben größer werden als 0. Die, die vorne sitzen, zum Beispiel im Mittel stellen sie 10 Fragen, die, die hinten sitzen, stellen im Mittel 2 Fragen, kommt eine Differenz von 8 raus, das µ ist gleich 8, ist also größer als 0. Wir würden davon ausgehen, dass wir eben in einer Welt leben, in der die Alternativhypothese gilt, in der Studierende, die vorne sitzen, eben mehr Fragen stellen. Hier sehen wir also die Verteilung der, sozusagen der Anzahl der Fragen, die Studierende stellen unter der Nullhypothese und hier unter der Alternativhypothese. Wir sehen, dass sich diese Welten sozusagen überschneiden können. Wir haben hier einen Überschneidungsbereich. Ja, und in diesem Überschneidungsbereich, also nochmal, das ist die, unsere theoretische, unsere theoretische Verteilung für eben die Population, gültig für die Nullhypothese und hier für die Alternativhypothese und die überschneiden sich hier an dieser Stelle. Das heißt auch, dass man sich falsch entscheiden kann, letztlich, weil ein Erwartungswert, der hier, also sozusagen ein Ergebnis, eine Beobachtung, die in diesen Bereich fällt, die kann auch noch zur Nullhypothese gelten, also zur Nullhypothese, Nullhypothesenwelt gehören, was aber sehr unwahrscheinlich ist. Also das wäre sehr unwahrscheinlich hier. Es wäre doch viel wahrscheinlicher, dass eine Beobachtung, die hier liegt, eben in die Welt der Alternativhypothese fällt. Ich habe das hier mal abgetragen. Um also festzustellen, welche Welt gilt, wird ein Anteil der Kurve der H0 hier abgetragen, bei dem die Wahrscheinlichkeit sehr gering ist, dass der empirische Wert, den wir herausbekommen, wenn er eben dort liegt, dann zur H0 gehört. Typischerweise legen wir dieses P, dieses Signifikanzniveau, ab dem Moment, wo wir uns entscheiden, okay, wenn es so, wenn sozusagen dieses P hier so klein wird, die Wahrscheinlichkeit, dass der empirische Wert, den wir jetzt durch unsere Beobachtung messen, wenn der zu einem nur sehr kleinen Teil hier in diese Kurve fällt, also sehr unwahrscheinlich ist, dass er in diesem Bereich fällt, dann gehen wir davon aus, dass ja eben, dass die Alternativhypothese gilt und dieser Grenzwert, den müssen wir, bevor wir eine Untersuchung machen, festlegen, also ab welchem P-Wert wir davon ausgehen, dass die Alternativhypothese gilt und den wählen wir, diesen P-Wert wählen wir sehr, sehr klein, um eben nicht, um eben keinen Fehler zu machen, und dann üblicherweise in der Psychologie liegt dieser P-Wert bei 0,05 Punkten, sprich bei 5 Prozent. Machen wir es konkreter. Wir ziehen also eine Stichprobe. Wie schon gesagt, ich nehme jetzt eine Vorlesung und halte innerhalb dieser Vorlesung fest. Wie viele Fragen denn die Studierenden in den ersten vier Reihen stellen, kriegt vielleicht mit, über so eine ganze Vorlesungsreihe, dass im Durchschnitt zehn Fragen aus den ersten vier Reihen kommen pro Vorlesung und aus den hinteren vier Reihen stellen eben sieben Studierende Fragen. Jetzt natürlich die Frage, ist dieser Unterschied eben nur zufällig zustande gekommen oder spiegelt dieses Ergebnis aus meiner Stichprobe die wahren Verhältnisse der Population wieder? Ich trage also ab, hier die Anzahl der Studierenden und die Anzahl der Fragen und jetzt sehen wir hier, das ist jetzt also die, ein Histogramm über die Studierenden in den hinteren Reihen und da stellen wir eben fest, dass vor allem mal 3, mal 4, mal 5, mal 6 Fragen gestellt wurden und hier sehen wir ja schon an der x-Achse, sie ist anders beschriftet, in den vorderen Reihen wurden eben mal 5, mal 6, mal 7, mal 8 Fragen eben gestellt. Wir kriegen im Mittel für die hinteren eben heraus sieben Fragen stellen und in den vorderen Reihen eben zehn Fragen stellen, macht einen Unterschied von drei Fragen. Nun muss ich mich fragen, wie wahrscheinlich ist es denn, dass, ich mach nächste Folie an, wie wahrscheinlich ist es denn, dass mein empirisches Ergebnis, sprich diese drei Fragen, Unterschied, die ich herausgefunden habe, wie wahrscheinlich ist es, dass dieses Ergebnis in der Welt zutreffen kann, die ich mit der H0 beschrieben habe. Wenn ich also annehme, dass die H0 gilt, dass ich in einer Welt lebe, in der vorne sitzende Studierende und hinten sitzende Studierende gleich viele Fragen stellen und ich mache eine empirische Forschung und bekomme jetzt eine solche Differenz eben von drei Fragen von vorne zu hinten Sitzenden, wie wahrscheinlich ist das denn? Und wenn ich jetzt eben hier herausbekomme, dass ich mich in einem sehr unwahrscheinlichen Fall bewege, also mein p kleiner wird als 0,05, sprich ich eine Wahrscheinlichkeit von 5% erhalte, dann entscheide ich mich dafür, dass die H1 gilt, weil in der ist ein solches Ergebnis, wie ich es in meiner Empirie habe, viel wahrscheinlicher. Also mit der höchsten Wahrscheinlichkeit tritt ein Wert eben auf, der hier an der Spitze dieser Verteilung liegt, eben hier µ0, das wäre der Erwartungswert unter der Hypothese, unter der Nullhypothese und hier ist der Erwartungswert eben µ1, der Erwartungswert unter der Alternativhypothese, Erwartungswert eben deshalb, weil das eben der am ehesten erwartbare Wert ist. Nun streuen aber solche Werte ja womöglich, deswegen haben wir hier eben so eine Verteilungs-, so eine Streuungskurve. Das bringt uns zum Begriff der statistischen Signifikanz. Das Ergebnis eines Signifikanztests ist dieser empirische p-Wert. Statistische Signifikanz wird hauptsächlich, nicht ausschließlich, aber hauptsächlich durch diese p-Entscheidungsregel bestimmt. Die ist wichtig, die sollten Sie sich merken. Wenn wir also einen hohen p-Wert haben, ja, man kann ja zum Beispiel trotzdem, also man könnte ein oder zwei Unterschiede, ein oder zwei Studierende im Mittelunterschied zwischen vorne und hinten feststellen. So ein Mittelmaß, das kann eine Streuung haben und wenn wir einen hohen p-Wert haben, sagen wir, okay, im Mittel unterscheiden sich zwar, sehen wir vielleicht einen Unterschied im Mittelwert zwischen vorderer und hinterer Reihe, der hohe p-Wert sagt uns aber, dass dieser Unterschied eben nicht statistisch signifikant ist, eben weil zum Beispiel die Streuung so groß ist, dass der Mittelwert an der Stelle eben keinen Aussagewert hat. Ein Ergebnis ist statistisch dann signifikant, wenn die empirische Wahrscheinlichkeit p-Empirisch kleiner als 5% ist. 5% ist eben das von uns festgelegte Kriterium, der theoretische p-Wert. Den kann man auch anders festlegen. Man kann ihn auch eben in der Medizin häufig auf ein Prozent oder noch kleiner festlegen, weil man noch sicherer mit seiner Aussage sein möchte, zum Beispiel ob ein Medikament mit hohen Nebenwirkungen aber immerhin hilft. Dann möchte ich eben sehr sicher sein, dass dieses hilft, dass ich mich eben sehr sicher für die Hypothese H1 entscheide. Ja, diese Wahrscheinlichkeitsgrenze, die wir da festlegen, heißt eben Signifikanzniveau, wird auch vereinzelt als Irrtumswahrscheinlichkeit bezeichnet. Der empirische p-Wert gibt nun an, mit welcher Wahrscheinlichkeit das gefundene Stichprobenergebnis oder auch ein extremeres Ergebnis auftreten kann, wenn die Nullhypothese zutrifft. Wenn es sehr unwahrscheinlich ist, dass die Nullhypothese zutrifft, wir kriegen also einen niedrigen empirischen p-Wert heraus, unter 5%, also wenn es sehr unwahrscheinlich ist, dass das Stichprobenergebnis, was wir gezogen haben, in die H0 fällt, dann gehen wir von einem signifikanten Ergebnis aus. Also nochmal zusammenfassend, wir machen mit der H0 eine Welt auf, in der wir, ja, also eine Verteilung, eine Welt auf. So, jetzt testen wir diese Welt mithilfe von Stichproben, die wir ziehen und gucken, der Wert, den wir jetzt testen in unserer Welt, passt der zu dieser von uns theoretisch aufgemachten H0-Welt? Und da gibt es Bereiche, wenn der Wert eben in einen Bereich, wo die Spitze der Verteilung ist, einfällt und sagen wir, okay, das haben wir erwartet, dass es irgendwo da landet, da landet auch tatsächlich unser empirischer Wert. Wir gehen davon aus, dass diese Welt, diese H0-Welt, die reale ist, dass wir in dieser Welt leben. Wenn wir jetzt aber uns diese H0-Kurve anschauen und, also diese Verteilung unter der H0 anschauen und jetzt über unsere Empirie einen Wert bekommen, der irgendwo hier links oder rechts an diesen Ausläufern dieser Kurve liegt, ja, diese Ausläufer bezeichnen dann halt, dass es immer unwahrscheinlicher wird, deswegen gehen sie eben zur Seite, immer unendlich, ja, nähern sich immer der Null an, immer weiter der Null an. Wenn irgendwo in diesen Grenzbereichen dieser Verteilung unser empirisch erhobener Wert liegt, dann glauben wir nicht mehr, dass der eben zu dieser H0-Welt gehört, sondern nun gehen wir davon aus, dass er eben in die H1-Welt gehört. Tja, und ich habe es jetzt schon ein paar mal angesprochen, man kann bei dieser Entscheidung, das ist ja eine Entscheidungsregel, die wir treffen, ab einem bestimmten Wert, wie weit da etwas außerhalb dieser Wahrscheinlichkeitsverteilung liegt, je weiter rechts oder je weiter links das da liegt, desto eher entscheide ich mich eben für etwas anderes. Da haben wir ja eine klare Grenze gelegt, das Signifikanzniveau. Typischerweise in der Psychologie bei 5%, dass wir sagen, okay, wenn diese Irrtumswahrscheinlichkeit unterschritten wird, dann gehen wir davon aus, dass eben die H1 gilt, wir in einer Welt der H1 leben. Dabei kann man aber Fehler machen. Ja, wir können also uns je nachdem, wie unser Test auslief, eben für etwas entscheiden. Gehen wir diese vier Feldertafeln hier einmal durch. Angenommen, in der Population gilt die H0. In unserem Beispiel jetzt kein Unterschied zwischen vorne und hinten sitzenden Studierenden. Und nach meinem Test, den ich gemacht habe, entscheide ich mich auch für die H0 und sage, die Daten legen jetzt nah, wir haben einen großen p-Wert, der eben über 5% liegt. Ich gehe davon weiterhin davon aus, dass wir in einer H0-Welt leben. Dann habe ich mich richtig entschieden. Was hier tatsächlich in der Population gilt, das kann im Grunde nur der Gott der Statistik oder auch die Göttin der Statistik wissen. Ja, deswegen ist das halt eine theoretische Betrachtung hier. Aber mal angenommen, in der Population gilt tatsächlich die H0. Die Welt ist eine H0-Welt. Ich mache einen statistischen Test, ein Experiment, was ich dann eben mit Statistik überprüfe und stelle fest, es scheint die H0 zu gelten. Dann habe ich mich richtig entschieden. Leben wir aber in einer Welt, in der die H0 gilt, wir machen ein Experiment, kriegen in dem Experiment einen empirischen p-Wert kleiner als 5% raus, entscheiden uns für die H1, sagen, oh, wir haben ein Experiment gemacht, es scheint etwas Neues zu sein. Wir scheinen nicht in der H0-Welt zu leben, sondern wir scheinen in der H1, in dieser Alternativwelt, wo eben vorne sitzende Studierende mehr Fragen stellen als hinten sitzende Studierende. Wir scheinen in einer solchen Welt zu leben. Dann entscheiden wir uns ja für die A1. Wenn aber tatsächlich, weil wir es ja nicht wissen, wenn wir tatsächlich in einer H0-Welt aber leben, dann sind wir in dem Moment, dann haben wir einen Fehler gemacht, nämlich den sogenannten Alpha-Fehler. Den wollen wir gering halten. Diesen Alpha-Fehler wollen wir gering halten, weswegen wir eben das Signifikanzniveau besonders klein wählen. Wie gesagt, in der Medizin sogar noch kleiner als 5%, um eben diesen Fehler so selten wie möglich zu begehen. Okay, schauen wir uns den rechten Teil an. Es geht natürlich auch das Umgedrehte. Es kann sein, dass wir in einer Population leben oder dass wir in einer Welt leben, so wie ich es ja jetzt die ganze Zeit besprochen habe, dass wir in einer Welt leben, in der die H1 gilt, in der tatsächlich vorne sitzende Studierende mehr sagen, mehr Zwischenfragen stellen als hinten sitzende Studierende. In einer solchen Welt, also wenn wir in einer solchen Welt leben, in der das gilt, in der die H1 gilt, machen wir einen Test und in unserer Stichprobe, die wir ziehen, stellen wir aber fest, bei uns haben die vorne sitzenden Studierenden und hinten sitzenden Studierenden gleich viel gesagt. Das heißt, wir würden uns für die H0 entscheiden, obwohl die H1 gilt. In dem Falle machen wir den sogenannten Beta-Fehler. Wenn in der Welt die H1 gilt, wir machen einen Test, wir untersuchen unsere Studierenden, machen einen statistischen Test und kommen heraus, wir glauben, dass die H1 gilt, weil unser p-Wert eben unter 0,05, weil unser Statistikprogramm einen kleineren p-Wert als 0,05 ausgespuckt hat, dann haben wir uns richtig entschieden. Wir sehen, wir können uns auch trotz experimentellen Bemühungen, trotz wissenschaftlicher Methoden, können wir noch immer irren. Aber was wir versuchen ist, diesen Irrtum im Zaum zu halten, so klein wie möglich zu geschalten. Es gibt die Möglichkeit, Fehler zu machen. Aber wir haben über unsere wissenschaftliche Methodik, über die Anwendung von Statistik, erlangen wir mehr Sicherheit als bei Schlussfolgerungen, die eben alleinig auf Einzelfällen beruhen oder die aufgrund von anekdotischen Wissen oder von solchen Alltagsbeobachtungen erzeugt werden. Also wir machen solche statistischen Prüfverfahren, wir machen Wissenschaft, um möglichst richtige Entscheidungen zu treffen, um hoffentlich eben in einer Welt zu leben, wo wir alle schwaren Farben eben kennen. Halten wir also fest, Hypothesen sind Wahrscheinlichkeitsaussagen. Hypothesen beinhalten allgemeingültige Aussagen bezüglich bestimmter Populationen, sagten wir. Diese Population ist eine Gesamtmenge von Individuen, eben alle Stier in der Welt, über die wir eine Aussage machen wollen. Diese Populationen können wir aber in der Regel nicht vollständig, sondern eben nur in Auszügen, in sogenannten Stichproben untersuchen. Die wählen wir zufällig, wir nehmen also eine Teilmenge aus dieser Population, die bestmöglich eben repräsentativ für die gesamte Population sein soll. Also repräsentativ heißt, dass die Stichprobe, die wir ziehen, bestmöglich in ihren Eigenschaften mit der Population übereinstimmt. Wir können aber nie alle Populationsmitglieder erfassen, in den wenigsten Fällen, dann bräuchten wir im Prinzip auch keine Inferenzstatistik, also keine solch signifikanten Ergebnisse. Und da wir eben nie alle Populationsmitglieder erfassen können, ist eine Endgültigkeit der Aussage, also ein endgültiges Verifizieren und auch ein endgültiges Falsifizieren nicht möglich. Hypothesen sind also Wahrscheinlichkeitsaussagen. Sie können nicht endgültig widerlegt werden, sie können aber auch niemals endgültig bestätigt werden. Hypothesen, wie wir sie jetzt kennengelernt haben, lassen eben aber auch Gegenbeispiele zu, wie die von dem Großvater, der eben doch noch, der eben alt geworden ist, obwohl er raucht, weil es eben, weil Wahrscheinlichkeitsaussagen eben immer auch Ausnahmefälle zulässt. Ein Ausweg ist, dass wir wissenschaftliche Prüfkriterien festlegen und eben statistische Verfahren nutzen. Ein Signifikanztest überprüft also, ob der Wert, den wir ermittelt haben, dieser empirische Wert, zufällig entstanden sein kann oder ob er eben nicht mehr zufällig entstanden sein kann oder ob wir eben es nicht mehr wirklich glauben können, dass er zufällig zustande gekommen sein kann. Und dafür müssen wir eben wissenschaftliche Prüfkriterien festlegen. Die Auswahl angemessener statistischer Prüfverfahren, das basiert dann eben auf folgenden Kriterien, zum Beispiel an der Anzahl der gemessenen Merkmale, also was ich eigentlich messe. Auch die Art der Hypothese beeinflusst dann, welchen Test wir rechnen können. Es ist eine Unterschiedshypothese, es ist eine Zusammenhangshypothese. Der Umfang und die Anzahl der Stichproben, die ich ziehe, hat einen Einfluss auf das Prüfverfahren, was ich dann nehmen kann. Auch die Art der Stichprobe, ist es eine abhängige Stichprobe, sind es unabhängige Stichproben. Und letztlich das Skalenniveau, mit dem ich meine Daten erhebe. Und das schauen wir uns alles an. Schauen wir uns als nächstes ein Beispiel einer solchen Forschungsfrage genauer an.
