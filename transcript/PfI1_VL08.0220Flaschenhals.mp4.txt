Wenn Sie sich jetzt mal ganz bewusst in Ihrem Raum umschauen, werden Sie womöglich feststellen, wie viele der Sachen, die Sie umgeben, gar nicht in Ihrem Bewusstsein sind, solange Sie nicht selbst Aufmerksamkeit darauf legen, z.B. wie voll gerade Ihre Tasse ist oder welches Buch vielleicht in Ihrem Regal ein wenig weiter voraussteht als andere Bücher oder vielleicht auch, wenn Sie sich heute schon den ganzen Tag hier mit dem Studium beschäftigt haben, wie das Wetter eigentlich draußen ist. Wir sehen also, dass unsere Umwelt voll von Reizen ist, denen wir keine Aufmerksamkeit schenken und die uns daher gar nicht sonderlich bewusst sind. Und ja, wenn so verschiedene Reize auf uns eintreffen und von uns verarbeitet werden wollen, dann konkurrieren die untereinander, welchen wir nun Aufmerksamkeit schenken. Und wir schauen uns jetzt am heutigen Tag oder in der jetzigen Vorlesung an, wie die Aufmerksamkeit, die selektive Aufmerksamkeit vor allen Dingen im auditiven Bereich ist, also über unsere Ohren. Und dabei stellen wir uns zwei relevante Fragen. Aber zunächst halten wir fest, die Aufmerksamkeit ist also ein Zustand fokussierten Bewusstseins auf eine Teilmenge der verfügbaren perzeptuellen Informationen, die also um uns drum herum sind. Aufmerksamkeit ist also eine Informationsselektion. Und die Frage, die wir uns nun stellen, ist, anhand welcher Merkmale werden denn diese Informationen ausgewählt und eben mit Aufmerksamkeit belegt? Und wenn wir uns den Informationsverarbeitungsprozess anschauen, wann findet denn die Selektion statt? Nehmen unsere Ohren einfach gar nicht, wenn ich jetzt sage, hören Sie mir bitte zu, nehmen unsere Ohren jetzt alles drumherum einfach gar nicht wahr? Trifft das gar nicht erst sozusagen auf unsere Sinne? Oder wird das später in höheren kognitiven Ebenen erst ausgeblendet oder abgedämpft oder wie auch immer? Und die ersten Informationen dazu, um diese Fragen zu beantworten, hat man eben mit akustischen Stimuli gemacht. Das hat ja ganz praktische Gründe, denn unsere Ohren können wir nicht wegbewegen oder verschließen. Mit unseren Augen, wenn ich Ihnen jetzt hier was präsentieren will, könnten Sie immer noch woanders hingucken oder die Augen zumachen. Wenn ich Ihnen jetzt aber als Experimentator einen Kopfhörer aufsetze und Ihnen da eine Aufgabe gebe, dass Sie auf das eine Ohr oder auf das andere Ohr achten sollen, was dort gesagt wird oder so ähnlich, dann können Sie da nicht weghören. Das heißt, dass jede Art von Selektivität, die in der Verarbeitung von Reizen zu beobachten ist, also die ich als Versuchsleiter jetzt bei Ihnen beobachte und bei allen anderen Probanden, geht also auf zentrale, interne Verarbeitungsprozesse zurück und eben nicht darauf, dass Sie mechanisch Ihre Ohren zuhalten oder wegschauen. Später natürlich hat man auch für den Sehsinn Kontrollmöglichkeiten geschaffen, dass man eben Eye-Tracking hatte, gesehen hat, wo schauen die Leute hin oder auch untersuchen konnte, haben die gerade geblinzelt oder nicht, aber anfangs hat man das eben über die Ohren gemacht. Wir haben in anderen Zusammenhängen schon festgestellt, dass die menschliche Informationsverarbeitung auf den frühen Stufen massiv parallel ist, also dass im sensorischen Register, ja das, was direkt bei unseren Sinnen ankommt, ich habe schon Speicher und ikonische Speicher schon mal kennengelernt, dort trifft eine enorme Anzahl an Informationen auf uns im üblichen Alltag. Aber unsere Alltagserfahrung zeigt auch, dass unsere Fähigkeit, mehrere Dinge simultan zu verarbeiten, sehr stark begrenzt ist. Wir können eben nicht Radionachrichten hören, ein Buch lesen und uns dabei noch unterhalten, ohne dass nicht irgendeiner dieser Tätigkeiten mit zu wenig Aufmerksamkeit im Prinzip geschenkt werden kann, dass dem zu wenig Aufmerksamkeit geschenkt werden kann. Die Schlussfolgerung also ist, dass ab einem bestimmten Punkt diese parallele Verarbeitung nicht mehr möglich ist. Und dort, wo das nicht mehr möglich ist, dort erfolgt der Übergang zu einer seriellen Verarbeitung. Das kann man sich im Grunde wie ein Flaschenhals vorstellen. Kommen wir auch gleich noch mal darauf zurück. Nur hier mal ein kleiner Exkurs, wie man sowas überhaupt abschätzen kann. Also ich habe es hier überschrieben mit Flaschenhalsmodell zur Enge des Bewusstseins. Also wie viel überhaupt von dem, was hier von der Umwelt auf uns trifft, tatsächlich von unserem Bewusstsein, ja oder was überhaupt in unser Bewusstsein gelangen kann. Ja und jetzt kann man das versuchen abzuschätzen. Wie genau das ist, das kann ich Ihnen jetzt hier nicht garantieren, aber lassen wir uns für den Exkurs mal darauf ein. So eine Informationsreduktion, wie wir sie hier sehen, die kann durch Methoden der neueren Informationstheorie, der Kybernetik, abgeschätzt werden. Ja und aus der Kybernetik stammt der Ansatz, dass wir die kleinste Informationseinheit als Bit bezeichnen. Das kennen Sie alle. Ein Bit unterscheidet zwischen zwei Zuständen von einer binären Entscheidung. Ja, na gut, eine binäre Entscheidung kann immer nur zwei Zustände haben, aber eben unterscheidet zwei Zustände, zumeist 0 oder 1. Und nun angenommen, der Mensch könne 256 Helligkeitsstufen psychophysisch unterscheiden. Das wären dann 256 ist das gleiche wie 2 hoch 8, das sind also 8 Bit. Und das, diese 8 Bit können wir nun multiplizieren mit der Anzahl der Bildpunkte in der Retina und der Anzahl der unterscheidbaren Bilder, die wir pro Sekunde sehen können. Ja, wenn Sie so ein Daumenkino machen, sobald da mehr als 20 oder 25 Bilder pro Sekunde durchrauschen, nehmen Sie nicht mehr einzelne Bilder wahr. Und so kommt man auf insgesamt 3 Millionen Bit pro Sekunde an Informationskapazität, die im Auge sozusagen landet. Also 3 Millionen Bit pro Sekunde. Und dann haben wir ja nicht nur das Auge, sondern dann haben wir auch noch andere Sinneseindrücke. Wir lesen aber zum Beispiel nur mit so etwa drei Wörtern pro Sekunde. Und das könnte eine Schätzung sein für die Kapazität, was pro Sekunde überhaupt in unser Bewusstsein gelangen kann. Sonst könnten wir vielleicht viel schneller lesen. Sprich, wie viel Informationen pro Sekunde wir bewusst verarbeiten können, liegt also nur so bei 20 bis 60 Bit pro Sekunde. Es scheint also eben diesen Flaschenhals hier zu geben, der die große Informationsmenge, die auf unsere Sensoren trifft, einschränkt. Keidel 1973, da müssen Sie sich ja nicht merken, nannte das die Abstraktion des Wesentlichen. Interessant hier ist noch, dass der motorische Output, das, was wir also nach außen wiedergeben an die Umwelt, der scheint wieder eine ähnliche Informationsmenge zu haben, wie das, was reinkommt. Ja, wenn wir sprechen, zeigen wir auch gleichzeitig Mimik. Ich gestikuliere gerade, ziehe vielleicht meine Augenbrauen hoch oder dergleichen. Und vieles davon tun wir ja unbewusst. Und dadurch können wir eben wieder mehr Informationen ausgeben. Aber das nur als kleiner Exkurs hier zum Flaschenhals, zur Enge des Bewusstseins. Dass wir ja Informationen eben seriell und nicht parallel verarbeiten können, das passiert auch schon bei sehr einfachen Aufgaben. Zeigt zum Beispiel ein Experiment von Welford schon 1952. Der Aufbau hier war, dass den Versuchspersonen zwei verschiedene Töne dargestellt oder wiedergegeben, dargeboten wurden. Und zwar ein hoher Ton, hier als Stimulus 1 bezeichnet, S1, und ein tiefer Ton, hier als Stimulus S2 bezeichnet. Und die Aufgabe der Versuchspersonen war nun, zu identifizieren, ob das eben ein hoher Ton oder ein niedriger Ton war. Deswegen hier R1 und R2 steht für Response. Wenn es sich um einen hohen Ton handelte, sollten sie die rechte Taste drücken, das ist Response 1, und die linke Taste drücken bei einem tiefen Ton, das ist Response 2. Wir haben also hier noch ein bisschen veranschaulicht. Wir haben also ein Stimulus, S1, und irgendwann wird, wenn das ein hoher Ton war, also ein S1-Ton war, dann gibt der Proband eine R1-Antwort. Und dazwischen passiert ein wenig Zeit, weil man hat ja eine gewisse Reaktionszeit, man muss das ja erstmal verarbeiten, überlegen, war das jetzt ein hoher oder niedriger Ton, und dann die Antwort geben. Nun kann man aber das Intervall zwischen S1 und S2, also es gibt zwei Töne, die hintereinander kommen, verändern. Wir hören hier Ton 1 und hier Ton 2, und die Zeit, die dazwischen liegt, wird auch als Stimulus-Onset-Synchrony bezeichnet, also das Intervall zwischen S1 und S2. Und Versuchspersonen sollen eben sowohl auf S1 sagen, ob das ein hoher Ton war, als auch auf S2 sagen, ob das ein hoher oder niedriger Ton war. Und entscheidend hier in dem Experiment ist, das ist hier angedeutet, dass dieser zweite Ton dargeboten wurde, noch bevor die Reaktion R1 überhaupt erfolgen könnte. Nun können Sie sich ja kurz einen Moment nehmen, zu überlegen, was jetzt hier eine passende UV und AV ist, bei diesem Experiment. Ich will Sie da aber gar nicht so lange auf die Folter spannen, denn die unabhängige Variable ist nun die Stimulus-Onset-Synchrony, oder SOA, SOA. Manchmal sage ich auch SOA dazu. Wir haben also ganz viele verschiedene Durchgänge, auch als Trials bezeichnet, und hier variieren wir jetzt, wie lang die Zeit zwischen zwei Stimuli ist. Hier im gelben ist die ein bisschen größer als hier in dem grauen Durchgang. Und als abhängige Variable messen wir nun, wie lange Versuchspersonen für die Reaktion auf den zweiten Stimulus brauchen. Der erste interessiert uns gar nicht so sehr, sondern wir gucken, wie schnell reagieren die jetzt darauf, auf diesen zweiten Stimulus zu entscheiden, war das ein hoher oder niedriger Ton. Und im Ergebnis zeigt sich, dass je schneller die Stimuli aufeinander folgten, desto langsamer war die Reaktion auf den zweiten Stimulus, im Vergleich zur Einzelbeurteilung eines solchen Stimulus. Wir sehen hier die Grafik hier unten, wie weit die beiden Stimuli auseinander liegen und wie lang die Reaktionszeit auf den zweiten. Wir gucken uns immer nur die Entscheidung auf den zweiten Ton an. Dann ist die, wenn sie sehr nah beieinander liegen, brauchen die Personen deutlich länger, um zu entscheiden, dass das ein hoher oder niedriger Ton war, oder überhaupt auf diesen Ton zu reagieren, im Vergleich dazu, dass da mehr, also mehr als 400 Millisekunden vergangen sind. Und damit schlussfolgert man, dass die, weil man könnte jetzt sagen, dieser Entscheidungsprozess, der würde doch in dem Moment anlaufen, in dem Moment, wie der Stimulus 2 zu hören ist. Also wenn jetzt hier Stimulus 1 passiert ist, dann vergeht eine bestimmte Zeit, aber ich fange ja hier schon an zu entscheiden, war das jetzt ein hoher oder niedriger Ton. Das geht bis dahin. So, und dann kommt hier der zweite Stimulus und dann könnte ich ja auch anfangen zu überlegen, ab dem Moment, wie der zweite Stimulus kam, war das ein hoher oder niedriger. Und wenn die Verarbeitung parallel stattfinden würde, also die Entscheidungsverarbeitung sozusagen parallel stattfinden könnte, dann müsste ja die Zeit, die man benötigt bei dem ersten Ton und bei dem zweiten Ton gleich sein. Das ist sie aber nicht, weil man noch sozusagen, weil man noch im Entscheidungsprozess von dem ersten ist, scheint der Entscheidungsprozess für den zweiten, darauf folgenden Ton hinten anzustehen. Und erst wenn meine Entscheidung für den ersten fertig ist, war es ein hoher oder niedriger Ton, erst dann geht der Entscheidungsprozess los, was war eigentlich mit dem zweiten Ton? War der hoch oder niedrig? Und damit kann sich erklären, erklärt sich, warum die Reaktion auf den zweiten Stimulus eben länger ist, weil wir nicht parallel verarbeiten, sondern hintereinander die Sachen abarbeiten. Selbst bei so einfachen Sachen wie so einem Ton und einer Entscheidung war der hoch oder niedrig. Und das nannte man auch, oder das durchaus wichtiger Begriff, nennt man auch Psychological Refractory Period, also die Refraktärzeit, die Sie schon von Neuronen kennen, jetzt eben sozusagen psychologischerseits. Das ist also eine Verzögerung der Reaktion auf den zweiten Reiz. Wie gesagt, zur Erinnerung, den Begriff Refraktärzeit kennen Sie schon aus der Neurophysiologie, wo er die Periode bezeichnete, nach der ein Neuron in Ruhe ist, weil es eben kein neues Aktionspotenzial gerade geben kann. Und diese PRP, diese Refraktärzeit, wird eben von dem Stimulus-Onset-Synchrony beeinflusst. Das heißt, die Reaktionszeitverzögerung ist eine Funktion der Stimulus-Onset-Synchrony. Und die beiden PRP und SOA verhalten sich umgekehrt proportional. Und die Interpretation, ich habe sie gerade schon so ein wenig genannt, von Werfurt ist, dass es einen zentralen seriellen Flaschenhals gibt und wir eben nur eine begrenzte Kapazität der zentralen Informationsverarbeitung haben. Also Reize können nur nacheinander, sprich seriell, verarbeitet werden. Es gibt also einen Engpass. Es kann vielleicht auf unserem Ohr beide oder es treffen die Töne allesamt auf, die wir jetzt gerade unterscheiden müssen, in dem Fall eben zwei. Aber wenn wir die verarbeiten sollen, sprich eine Entscheidung treffen sollen, das ist ja eine höhere kognitive Aufgabe, die wir damit haben, dass wir da eine Entscheidung treffen müssen, das passiert eben nur seriell, deswegen hier der Flaschenhals. Hier habe ich die Erklärung versucht noch mal ein bisschen grafisch darzustellen, was ich Ihnen gerade schon erklärt habe. Es passiert S1, dann passiert eine Auswahl oder eine Verarbeitung, dann müssen wir natürlich noch auswählen, dann müssen wir jetzt den linken Taster oder den rechten Taster drücken. Und zwar passiert das Aufnehmen des S2 noch parallel, aber wir müssen erst abwarten, bis die Auswahl hier fertig ist, bevor wir hier mit der Auswahl für die Reaktion für den zweiten Ton weitermachen können. Und genau das Stückchen, was sich hier überlappt, also dass wir erst auf das Ende der Auswahl warten müssen, bevor wir die richtige Auswahl für RT, also für die zweite Reaktion machen können, das ist die Zeit, um die sich eben die Reaktion für den zweiten Stimulus verlängert. Und ähnliche Untersuchungen, aber mit etwas komplexerem Material, finden statt über die Methode des dichotischen Hörens. Und damit Sie kurz einen Eindruck davon bekommen, habe ich hier ein kleines Video mitgebracht. Dafür lohnt es Sie, oder dafür ist nötig, dass Sie entweder zwei, ja am besten zwei Ohrstöpsel parat haben, dass Sie da eben links, weil ich Ihnen gleich links und rechts eine Information aufs Ohr geben werde, oder hier das Video Ihnen aufs Ohr geben wird. Und Ihre Aufgabe, Sie sehen es da gerade, die Instruction, ist, dass Sie sich auf eines der beiden Ohren fixieren. Ich kann jetzt einfach mal festlegen, dass Sie alle auf das linke Ohr achten, aber natürlich nicht mogeln, sondern beide Ohrstöpsel ins Ohr stecken und Ihnen werden zehn Wörter präsentiert und danach schreiben Sie sich mal auf, welche Wörter Sie denn gehört haben. Lassen Sie uns mal zusammen reinhören. All right, so write down as many as you remember. And if you didn't hear two streams of information, it might be because your computer or your TV is mono-channel and only played one at a time, and so this will be really easy for you. But go ahead and write as many as you can. All right, you can pause it if you need to, to write down the rest. We're going to go over these. Five, Shred, Mechanical, Grasp, Philosophy, Barrow, Jeddow, Carcass, Godless. And those are the ten. Okay, das soll für uns für den Moment reichen. Das Video geht noch weiter, aber das, was danach folgt, ist eine Variation des Experiments, was wir uns gleich noch anschauen. Also, wir schauen in dieses Video gleich noch mal hinein. Nachdem Sie sich einen Eindruck verschafft haben, wie das so klingt, hier mal kurz überlegt, was ist das dichotische Hören denn überhaupt als Untersuchungsparadigma? Was untersucht man damit? In Werden also eine Sequenz von simultanen Ziffernpaaren. Jetzt hatten wir zwar Wörter und Ziffern, aber jetzt ganz ursprünglich wurden auf das linke Ohr und auf das rechte Ohr verschiedene Ziffern gegeben. Zum Beispiel auf das linke Ohr 2, 6 und 1 und auf das rechte Ohr 7, 9 und 5. Und die Aufgabe der Versuchsperson war es, die Ziffern wiederzugeben nach dieser, ja, das hat vielleicht anderthalb Sekunden gedauert, ja, die drei Ziffern aufs Ohr zu bekommen und danach sollten die Personen das fehlerfrei wiedergeben. Und das Interessante ist, was hier zum Beispiel Broadband 1954 herausgefunden hat, ist, dass Personen bevorzugt nach Ohr und nicht nach Darbietungspaar wiedergeben. Ja, also sie sagen jetzt nicht 2, 7, 6, 9, 1, 5 als Antwort, sondern sie sagen 2, 6, 1, linkes Ohr abgehakt, und dann 7, 9, 5, rechtes Ohr abgehakt. Nun kann man aber die Versuchspersonen auch bitten, dass sie, eben wenn sie auf ihre beiden Ohren unterschiedliche Sachen gehört haben, dass sie nur eines davon nachsprechen sollen, also dass sie sich ausschließlich auf ein Ohr konzentrieren sollen. Das nennt man auch Shadowing, also das Nachsprechen dessen, was auf ein Ohr kommt. Und da haben Cherry, aber auch Moray, haben das in den 50ern genutzt, dieses Paradigma, oder erstmalig genutzt, dieses Paradigma. Und hier stellt man fest, dass die Probanden und Probandinnen den Kanal, auf den sie sich fokussieren sollen, ja, also wenn ich jetzt von Kanal rede, können sie sich auch Ohr denken, also dass sie auf dem rechten Ohr die Informationen bitteschön nachsprechen sollen, shadowen sollen, und das können die ganz gut, sie können den gut verfolgen. Jetzt ist aber interessant, wie sieht es denn mit den Informationen aus, die auf dem anderen Kanal, auf dem anderen Ohr gegeben werden, auf das sie sich nicht konzentrieren sollen, auf das sie keine Aufmerksamkeit legen sollen. Die Informationen eben dieses anderen Kanals, die könnten verloren gehen, oder Cherry zeigte, dass sie verloren gehen, bis auf bestimmte Merkmale. Also man konnte zum Beispiel, die Probanden konnten noch sagen, ja, auf dem anderen nicht beachteten Kanal, das war eine männliche oder eine weibliche Stimme, oder das war ein lauter Piepton, oder so etwas. Das konnten die sehr wohl noch sagen. Und interessant ist, dass wenn man die Person mitten in der Aufgabe unterbrochen hat, immer noch erinnern sie sich, die Aufgabe ist es nur auf das eine Ohr zu achten, aber auf das andere werden trotzdem Informationen gegeben und unterbricht man die jetzt dabei, dann erinnern sie sich doch noch an so die letzten fünf bis sieben Wörter und Zahlen des nicht beachteten Kanals. Die Informationen scheinen also für kurze Zeit zur Verfügung zu stehen, gehen aber ohne Aufmerksamkeit verloren. Wenn sie die Vorlesung schon gesehen haben, so können sie das an die Experimente von Sperling erinnern, wo wir auch ein Hörsaal-Experiment dazu hatten. Ja, und in den nächsten Schritten wollen wir uns anschauen, welche Verarbeitungsprozesse denn diesen Beobachtungen, also diesen beobachtenden Eigenschaften der auditiven Aufmerksamkeit überhaupt zugrunde liegen. Und damit kommen wir zu Filtertheorien, zum Beispiel den von Broadband.
